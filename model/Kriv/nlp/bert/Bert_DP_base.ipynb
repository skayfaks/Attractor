{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,  roc_auc_score, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = AutoModel.from_pretrained('DeepPavlov/rubert-base-cased-sentence')\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('DeepPavlov/rubert-base-cased-sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3184, 12)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"df_pp_stem_lemm.csv\")\n",
    "df = df.drop('Unnamed: 0',axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>okpd_2</th>\n",
       "      <th>name</th>\n",
       "      <th>number</th>\n",
       "      <th>fz</th>\n",
       "      <th>date</th>\n",
       "      <th>preproccessed_name</th>\n",
       "      <th>preproccessed_okpd_2</th>\n",
       "      <th>preproccessed_name_stem</th>\n",
       "      <th>preproccessed_okpd_2_stem</th>\n",
       "      <th>preproccessed_name_lemm</th>\n",
       "      <th>preproccessed_okpd_2_lemm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>0</td>\n",
       "      <td>62.09.20.190: Услуги по технической поддержке ...</td>\n",
       "      <td>Оказание услуг по технической поддержке и обно...</td>\n",
       "      <td>№0817200000323015217</td>\n",
       "      <td>44</td>\n",
       "      <td>21.09.2023</td>\n",
       "      <td>оказание услуг по технической поддержке и обно...</td>\n",
       "      <td>услуги по технической поддержке в области инф...</td>\n",
       "      <td>оказан услуг техническ поддержк обновлен актуа...</td>\n",
       "      <td>услуг техническ поддержк област информацион те...</td>\n",
       "      <td>оказание услуга технический поддержка обновлен...</td>\n",
       "      <td>услуга технический поддержка область информаци...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>0</td>\n",
       "      <td>62.03.12.130: Услуги по сопровождению компьюте...</td>\n",
       "      <td>Оказание услуг по сопровождению программного п...</td>\n",
       "      <td>№0162200011823002478</td>\n",
       "      <td>44</td>\n",
       "      <td>26.09.2023</td>\n",
       "      <td>оказание услуг по сопровождению программного п...</td>\n",
       "      <td>услуги по сопровождению компьютерных систем</td>\n",
       "      <td>оказан услуг сопровожден программн продукт пар...</td>\n",
       "      <td>услуг сопровожден компьютерн сист</td>\n",
       "      <td>оказание услуга сопровождение программный прод...</td>\n",
       "      <td>услуга сопровождение компьютерный система \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment                                             okpd_2  \\\n",
       "1260          0  62.09.20.190: Услуги по технической поддержке ...   \n",
       "1000          0  62.03.12.130: Услуги по сопровождению компьюте...   \n",
       "\n",
       "                                                   name                number  \\\n",
       "1260  Оказание услуг по технической поддержке и обно...  №0817200000323015217   \n",
       "1000  Оказание услуг по сопровождению программного п...  №0162200011823002478   \n",
       "\n",
       "      fz        date                                 preproccessed_name  \\\n",
       "1260  44  21.09.2023  оказание услуг по технической поддержке и обно...   \n",
       "1000  44  26.09.2023  оказание услуг по сопровождению программного п...   \n",
       "\n",
       "                                   preproccessed_okpd_2  \\\n",
       "1260   услуги по технической поддержке в области инф...   \n",
       "1000        услуги по сопровождению компьютерных систем   \n",
       "\n",
       "                                preproccessed_name_stem  \\\n",
       "1260  оказан услуг техническ поддержк обновлен актуа...   \n",
       "1000  оказан услуг сопровожден программн продукт пар...   \n",
       "\n",
       "                              preproccessed_okpd_2_stem  \\\n",
       "1260  услуг техническ поддержк област информацион те...   \n",
       "1000                  услуг сопровожден компьютерн сист   \n",
       "\n",
       "                                preproccessed_name_lemm  \\\n",
       "1260  оказание услуга технический поддержка обновлен...   \n",
       "1000  оказание услуга сопровождение программный прод...   \n",
       "\n",
       "                              preproccessed_okpd_2_lemm  \n",
       "1260  услуга технический поддержка область информаци...  \n",
       "1000       услуга сопровождение компьютерный система \\n  "
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['name'] = df['name'].astype(str) + ' ' + df['okpd_2'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "после объединения столбца name и okpd_2 метрики стали хуже"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "               precision    recall  f1-score   support\n",
    "\n",
    "           0       0.96      0.96      0.96       471\n",
    "           1       0.54      0.53      0.53        38\n",
    "\n",
    "    accuracy                           0.93       509\n",
    "   macro avg       0.75      0.75      0.75       509\n",
    "weighted avg       0.93      0.93      0.93       509\n",
    "\n",
    "ROC-AUC: 0.9140127388535031\n",
    "Confusion Matrix:\n",
    "[[454  17]\n",
    " [ 18  20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размеры тренировочного датасета: (2547, 1) (2547,)\n",
      "Размеры тестового датасета: (509, 1) (509,)\n",
      "Размеры валидационного датасета: (128, 1) (128,)\n"
     ]
    }
   ],
   "source": [
    "train_df = df[['name','sentiment']]\n",
    "\n",
    "X = train_df.drop('sentiment', axis=1)\n",
    "y = train_df['sentiment']\n",
    "\n",
    "train_text, X_temp, train_labels, y_temp = train_test_split(X, y, test_size=0.20, random_state=42, stratify=train_df['sentiment'])\n",
    "test_text, val_text, test_labels, val_labels = train_test_split(X_temp, y_temp, test_size=0.20, random_state=42)\n",
    "\n",
    "test_df = pd.DataFrame({'sentiment': test_text['name'], 'label': test_labels})\n",
    "\n",
    "# Вывод размеров полученных датасетов\n",
    "print(\"Размеры тренировочного датасета:\", train_text.shape, train_labels.shape)\n",
    "print(\"Размеры тестового датасета:\", test_text.shape, test_labels.shape)\n",
    "print(\"Размеры валидационного датасета:\", val_text.shape, val_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "график длин предложений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_text['name'].apply(lambda x: len(tokenizer.encode(x))).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = train_text.astype(str)\n",
    "val_text = val_text.astype(str)\n",
    "test_text = test_text.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Токенизируем текста, передадим в тензоры и загрузим в функцию DataLoader, которая будет по частям подавать наши данные для обучения и валидации в модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_text['name'].values.tolist(),\n",
    "    max_length = 155,\n",
    "    padding = 'max_length',\n",
    "    truncation = True\n",
    ")\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    val_text['name'].values.tolist(),\n",
    "    max_length = 155,\n",
    "    padding = 'max_length',\n",
    "    truncation = True\n",
    ")\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    test_text['name'].values.tolist(),\n",
    "    max_length = 155,\n",
    "    padding = 'max_length',\n",
    "    truncation = True\n",
    ")\n",
    "\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.values)\n",
    "\n",
    "val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor(val_labels.values)\n",
    "\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(test_labels.values)\n",
    "batch_size = 8\n",
    "\n",
    "\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler = train_sampler, batch_size = batch_size)\n",
    "\n",
    "val_data =  TensorDataset(val_seq, val_mask, val_y)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT не обучаем. Допишем к его выходу свои слои, которые и будем обучать на классификацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in bert.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "class BERT_Arch(nn.Module):\n",
    "    \n",
    "    def __init__(self, bert):\n",
    "        super(BERT_Arch, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(768,512)\n",
    "        self.fc2 = nn.Linear(512,2)\n",
    "        self.softmax = nn.Softmax(dim = 1)\n",
    "    \n",
    "    def forward(self, sent_id, mask):\n",
    "        _, cls_hs = self.bert(sent_id, attention_mask = mask, return_dict = False)\n",
    "        x = self.fc1(cls_hs)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объявим модель, загрузим ее в GPU. Импортируем оптимизатор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = BERT_Arch(bert)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "               lr= 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для борьбы с дисбалансом классов используем следующий подход:\\\n",
    "вычисляем взвешенные классы на основе уникальных значений меток  `train_labels` . \\\n",
    "используем кросс-энтропию в качестве функции потерь и устанавливаете количество эпох для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5405348  6.66753927]\n"
     ]
    }
   ],
   "source": [
    "class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
    "print(class_weights)\n",
    "weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "weights = weights.to(device)\n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!!ВЕСА"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для обучения модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "    total_preds = []\n",
    "    \n",
    "    for step, batch in tqdm(enumerate(train_dataloader), total = len(train_dataloader)):\n",
    "        batch = [r.to(device) for r in batch]\n",
    "        sent_id,mask,labels = batch\n",
    "        model.zero_grad()\n",
    "        preds = model(sent_id, mask)\n",
    "        loss = cross_entropy(preds, labels)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        preds = preds.detach().cpu().numpy()\n",
    "        total_preds.append(preds)\n",
    "        \n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    total_preds = np.concatenate(total_preds, axis = 0)\n",
    "    \n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция валидации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    model.eval()\n",
    "    total_loss, total_accuracy = 0,0\n",
    "    total_preds = []\n",
    "\n",
    "    for step, batch in tqdm(enumerate(val_dataloader), total = len(val_dataloader)):\n",
    "        batch = [t.to(device) for t in batch]\n",
    "        sent_id, mask, labels = batch\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            preds = model(sent_id, mask)\n",
    "            loss = cross_entropy(preds, labels)\n",
    "            total_loss = total_loss + loss.item()\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "            total_preds.append(preds)\n",
    "\n",
    "    avg_loss = total_loss / len(val_dataloader)\n",
    "    total_preds = np.concatenate(total_preds, axis = 0)\n",
    "    \n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем. Для лучшей метрики на валидации сохраняем веса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch1 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/319 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 319/319 [00:29<00:00, 10.67it/s]\n",
      "100%|██████████| 16/16 [00:01<00:00, 11.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.247\n",
      "Validation loss: 0.198\n",
      "\n",
      " Epoch2 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 319/319 [00:30<00:00, 10.54it/s]\n",
      "100%|██████████| 16/16 [00:01<00:00, 11.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.195\n",
      "Validation loss: 0.198\n",
      "\n",
      " Epoch3 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 319/319 [00:30<00:00, 10.60it/s]\n",
      "100%|██████████| 16/16 [00:01<00:00, 11.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.189\n",
      "Validation loss: 0.189\n",
      "\n",
      " Epoch4 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 319/319 [00:30<00:00, 10.46it/s]\n",
      "100%|██████████| 16/16 [00:01<00:00, 10.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.179\n",
      "Validation loss: 0.184\n",
      "\n",
      " Epoch5 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 319/319 [00:30<00:00, 10.49it/s]\n",
      "100%|██████████| 16/16 [00:01<00:00, 10.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.178\n",
      "Validation loss: 0.175\n",
      "\n",
      " Epoch6 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 319/319 [00:30<00:00, 10.44it/s]\n",
      "100%|██████████| 16/16 [00:01<00:00, 10.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.170\n",
      "Validation loss: 0.222\n",
      "\n",
      " Epoch7 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 319/319 [00:30<00:00, 10.45it/s]\n",
      "100%|██████████| 16/16 [00:01<00:00, 10.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.176\n",
      "Validation loss: 0.183\n",
      "\n",
      " Epoch8 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 319/319 [00:30<00:00, 10.39it/s]\n",
      "100%|██████████| 16/16 [00:01<00:00, 10.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.169\n",
      "Validation loss: 0.180\n",
      "\n",
      " Epoch9 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 319/319 [00:30<00:00, 10.47it/s]\n",
      "100%|██████████| 16/16 [00:01<00:00, 10.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.164\n",
      "Validation loss: 0.161\n",
      "\n",
      " Epoch10 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 319/319 [00:31<00:00, 10.16it/s]\n",
      "100%|██████████| 16/16 [00:01<00:00, 10.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.153\n",
      "Validation loss: 0.168\n",
      "\n",
      " Epoch11 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 319/319 [00:30<00:00, 10.39it/s]\n",
      "100%|██████████| 16/16 [00:01<00:00, 10.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.150\n",
      "Validation loss: 0.167\n",
      "\n",
      " Epoch12 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 319/319 [00:30<00:00, 10.40it/s]\n",
      "100%|██████████| 16/16 [00:01<00:00, 10.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.147\n",
      "Validation loss: 0.201\n",
      "\n",
      " Epoch13 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 319/319 [00:30<00:00, 10.41it/s]\n",
      "100%|██████████| 16/16 [00:01<00:00, 10.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.160\n",
      "Validation loss: 0.159\n",
      "\n",
      " Epoch14 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 319/319 [00:30<00:00, 10.30it/s]\n",
      "100%|██████████| 16/16 [00:01<00:00, 10.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.147\n",
      "Validation loss: 0.176\n",
      "\n",
      " Epoch15 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 319/319 [00:30<00:00, 10.45it/s]\n",
      "100%|██████████| 16/16 [00:01<00:00, 10.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.149\n",
      "Validation loss: 0.216\n",
      "\n",
      " Epoch16 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 319/319 [00:30<00:00, 10.40it/s]\n",
      "100%|██████████| 16/16 [00:01<00:00, 10.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.145\n",
      "Validation loss: 0.187\n",
      "\n",
      " Epoch17 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 319/319 [00:30<00:00, 10.38it/s]\n",
      "100%|██████████| 16/16 [00:01<00:00, 10.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.142\n",
      "Validation loss: 0.182\n",
      "\n",
      " Epoch18 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 319/319 [00:30<00:00, 10.41it/s]\n",
      "100%|██████████| 16/16 [00:01<00:00, 10.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.146\n",
      "Validation loss: 0.172\n",
      "\n",
      " Epoch19 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 319/319 [00:30<00:00, 10.39it/s]\n",
      "100%|██████████| 16/16 [00:01<00:00, 10.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.145\n",
      "Validation loss: 0.184\n",
      "\n",
      " Epoch20 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 319/319 [00:30<00:00, 10.40it/s]\n",
      "100%|██████████| 16/16 [00:01<00:00, 10.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.140\n",
      "Validation loss: 0.210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_valid_loss = float('inf')\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "for epoch in range(epochs):\n",
    "    print('\\n Epoch{:} / {:}'.format(epoch+1, epochs))\n",
    "    train_loss, _ = train()\n",
    "    valid_loss = evaluate()\n",
    "    if valid_loss is not None:  # Проверка на None\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "        train_losses.append(train_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "        print(f'\\nTraining loss: {train_loss:.3f}')\n",
    "        print(f'Validation loss: {valid_loss:.3f}')\n",
    "    else:\n",
    "        print(\"Evaluation did not return a valid loss value.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------\n",
    "обучили модель и сохранили ее результат.\\\n",
    "проверим на тестовой выборке и использование на боевых данных.\n",
    "\n",
    "# Загрузим лучшие веса для модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'saved_weights.pt'\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видеопамяти не хватает для хранения всего что в нее передано, поэтому используем костыль.\\\n",
    "Разобиваю тестовые данные на части и буду отправлять на предсказание по частям"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_seq = np.array_split(test_seq, 50)\n",
    "list_mask = np.array_split(test_mask, 50)\n",
    "\n",
    "\n",
    "predictions = []\n",
    "for num, elem in enumerate(list_seq):\n",
    "    with torch.no_grad():\n",
    "        preds = model(elem.to(device), list_mask[num].to(device))\n",
    "        predictions.append(preds.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразую полученные предсказания в один список, нормализую данные и запишу в новый столбик датафрейма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_preds = [item[1] for sublist in predictions for item in sublist]\n",
    "flat_preds = (flat_preds - min(flat_preds)) / (max(flat_preds) - min(flat_preds))\n",
    "test_df['confidence'] = flat_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На выходе получили значение с плавающей точкой от 0 до 1.\\\n",
    " Теперь меняя порог, сможем предсказать финальный класс:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.84      0.91       471\n",
      "           1       0.30      0.84      0.44        38\n",
      "\n",
      "    accuracy                           0.84       509\n",
      "   macro avg       0.64      0.84      0.67       509\n",
      "weighted avg       0.93      0.84      0.87       509\n",
      "\n",
      "ROC-AUC: 0.9108838976421947\n",
      "Confusion Matrix:\n",
      "[[395  76]\n",
      " [  6  32]]\n"
     ]
    }
   ],
   "source": [
    "#развернуть трешхолд\n",
    "threshold = 0.75\n",
    "\n",
    "test_df['pred'] = test_df['confidence'].apply(lambda x: 1 if x > threshold else 0)\n",
    "\n",
    "print(classification_report(test_df['label'], test_df['pred']))\n",
    "\n",
    "roc_auc = roc_auc_score(test_df['label'], test_df['confidence'])\n",
    "print(f\"ROC-AUC: {roc_auc}\")\n",
    "\n",
    "conf_matrix = confusion_matrix(test_df['label'], test_df['pred'])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
